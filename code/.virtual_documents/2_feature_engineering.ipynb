import pandas as pd
from matplotlib import pyplot as plt
import numpy as np





data = pd.read_csv("data_preprocessed.csv")
data


### apply Variance Threshold
from sklearn.feature_selection import VarianceThreshold

selector = VarianceThreshold(threshold=0.01)
data_reduced = selector.fit_transform(data)

selected_features = data.columns[selector.get_support()]
data_reduced = pd.DataFrame(data_reduced, columns=selected_features)

removed_features = data.columns[~selector.get_support()]
print(list(removed_features))





import seaborn as sns

corr = data_reduced.corr()
plt.figure(figsize=(12, 10))
sns.heatmap(corr, annot=False, cmap="coolwarm")
plt.show()

#red → high positive correlation
#blue → high negative correlation
#white → weak or no correlation


# abs values
abs_corr = corr.abs()

# only upper triangular matrix to avoid duplicates
upper = abs_corr.where(np.triu(np.ones(abs_corr.shape), k=1).astype(bool))
threshold = 0.8

# find pairs with var higher than threshold
strong_pairs = [(col1, col2, upper.loc[col1, col2]) 
                for col1 in upper.columns 
                for col2 in upper.index 
                if pd.notnull(upper.loc[col1, col2]) and upper.loc[col1, col2] > threshold]

for col1, col2, corr_val in strong_pairs:
    print(f"[1]{col1}\n[2]{col2}: {corr_val:.2f}")



### Delete following questions:
# Is your employer primarily a tech company/organization?_0.0
# Have you heard of or observed negative consequences for co-workers who have been open about mental health issues in your workplace?_No
# Have you been diagnosed with a mental health condition by a medical professional?_No
# Have you ever sought treatment for a mental health issue from a mental health professional?_0
# What country do you live in?_Australia
# What country do you live in?_Brazil
# What country do you live in?_Canada
# What country do you live in?_France
# What country do you live in?_Germany
# What country do you live in?_Ireland
# What country do you live in?_Netherlands
# What country do you live in?_Other
# What country do you live in?_Sweden
# What country do you live in?_United Kingdom
# What country do you live in?_United States of America

cols_to_delete = [col for col in data_reduced.columns 
                  if "What country do you live in?" in col]

cols_to_delete += [
    "Is your employer primarily a tech company/organization?_0.0",
    "Have you heard of or observed negative consequences for co-workers who have been open about mental health issues in your workplace?_No",
    "Have you been diagnosed with a mental health condition by a medical professional?_No",
    "Have you ever sought treatment for a mental health issue from a mental health professional?_0"
]

data_reduced = data_reduced.drop(columns=cols_to_delete)


# show all questions
for col in data_reduced.columns:
    print(col)


data_reduced.to_csv('data_reduced.csv', index=False)








from sklearn.decomposition import PCA

pca = PCA()
X_pca = pca.fit_transform(data_reduced)


### EXPLAINED VARIANCE PLOT
plt.plot(range(1, len(pca.explained_variance_ratio_)+1),
         pca.explained_variance_ratio_)
plt.xlabel("Komponente")
plt.ylabel("Erklärte Varianz")
plt.show()



### CUMULATIVE EXPLAINED VARIANCE PLOT
plt.figure(figsize=(10, 6))

plt.plot(range(1, len(cumulative_variance) + 1),
         cumulative_variance)

target_variance = 0.85
n_components = np.argmax(cumulative_variance >= target_variance) + 1

plt.axhline(y=target_variance, color='r', linestyle='--', label=f'{target_variance*100}% variance')
plt.axvline(x=n_components, color='r', linestyle=':', label=f'components for {target_variance*100}%: {n_components}')

plt.xlabel('number of components')
plt.ylabel('cumulative explained variance')
plt.grid(True)
plt.legend()
plt.show()


pca = PCA(n_components=64)
X_pca = pca.fit_transform(data_reduced)


explained_variance = pca.explained_variance_ratio_
print("explained variance: ",explained_variance)
print("cumulative variance: ", explained_variance.cumsum())



import joblib
joblib.dump(pca, "pca_model.joblib")
np.save("X_pca.npy", X_pca)




