\chapter{Datenbeschreibung und Explorative Datenanalyse}
Im Rahmen der Exploratory Data Analysis wurde der Datensatz auf Struktur, 
Verteilungen, fehlende Werte und potenzielle Inkonsistenzen untersucht. 
Dabei wurden zentrale Merkmale analysiert und erste Muster identifiziert, 
die Hinweise auf relevante Einflussfaktoren psychischer Belastung liefern. 
Die Ergebnisse der EDA bilden die Grundlage für die anschließende Vorverarbeitung 
und das Feature Engineering.

\section{Herkunft und Struktur des Datensatzes}
- Quelle (z. B. Kaggle OSMI Mental Health in Tech 2016)\\
- Stichprobe beschreiben, Anzahl der Merkmale, Datentypen\\
- Besonderheiten: Freitextfelder, kategoriale Felder, sensible Daten
\begin{itemize}
    \item Also Quelle ist https://www.kaggle.com/datasets/osmi/mental-health-in-tech-2016?resource=download
    \item Die OSMI Mental Health in Tech Survey 2016 ist eine internationale Umfrage mit 
über 1400 Teilnehmern aus dem IT- und Tech-Bereich. Ziel der Umfrage ist es, 
Einstellungen gegenüber psychischer Gesundheit am Arbeitsplatz zu erfassen und 
die Häufigkeit psychischer Erkrankungen unter Beschäftigten in der Tech-Branche 
zu untersuchen. Die gesammelten Daten werden vom Open Sourcing Mental Illness (OSMI) 
Team genutzt, um das Bewusstsein für psychische Gesundheit zu stärken und die 
Arbeitsbedingungen für Betroffene in der IT zu verbessern.
    \item 1433 Zeilen also Teilnehmer und 63 Spalten also Fragen.
    \item Datentypen sind int64, float64 und hauptsächlich object also eine Texteingabe.
    \item Fehlende Werte gibts i.d.R. viele (siehe Heatmap). Zwischen Fragen 0 bis 36 gibts
immer wieder Leute die nichts eingetragen haben. Die meisten fehlende Werte liegen
zwischen Frage 16 und 24. Das sind Fragen wie:\\
- "Do you have medical coverage 
(private insurance or state-provided) which includes treatment of  
mental health issues?\\
- If you have been diagnosed or treated for a mental health disorder, do you 
ever reveal this to coworkers or employees?\\
- Do you believe your productivity is ever affected by a mental health issue?\\
Also konkrete und stark private Fragen, die jedoch am meisten zum Thema beitragen
\end{itemize}

\section{Erste deskriptive Analysen???}
- Verteilungen wichtiger Merkmale (Gender, Age, Wohnland/Arbeitsland)\\
- Identifikation möglicher Probleme: Outlier, Inkonistenzen\\
\begin{itemize}
    \item es wurden basisdaten analysiert wie GENDER, AGE, WOHNLAND und Arbeitsland
    \item Da GENDER keine vordefinierte Antworten hatte, hat jeder Befragte seine eigene 
Antwort geschrieben, was dazu führt dass danach eingie Gruppen zusammengeführt werden
müssen (wie Female, female, f) und andere komplett entfernt (z.B. Dude, mail)
    \item beim AGE gibts Ausreißer über 100 und 300 Jahre analysiert
    \item Arbeitsland und Wohnland sehen gut aus, hier zeigt sich dass der Großteil
aus USA und UK kommt
    \item Die Befragten arbeiten hauptsächlich in dem Land in dem sie wohnen (1407:26)
\end{itemize}



\chapter{Datenvorverarbeitung}

\section{Umgang mit fehlenden Werten}
- Identifikation der fehlenden Werte (siehe Heatmap)\\
- Strategien (z. B. Dropping, Imputation, Domain-Knowledge)\\
- Begründung der gewählten Methode\\
\begin{itemize}
    \item zuerst werden alle offenen Fragen gelöscht die schwer von KI zu
interpretieren sind für eine Clustering Aufgabe (z.B. Why or why not?) und Fragen
die auf vorherige Antwort bezogen sind also (What US state do you work in/live in?)
    \item bezüglich fehlenden Werten werden zuerst Befragte gesucht die von allen
Fragen mehr als 40\% unbeantwortet haben. Diese entfernen!
    \item jetzt die Fragen die mehr als 40\% missing ratio haben werden gelöscht
    \item Befragte die weniger als 20\%fehlende Werte haben, werden durch Imputation
ergänzt.
    

\end{itemize}

\section{Bereinigung unstandardisierter Texteingaben???}
- Vereinheitlichung von Kategorien\\
- Lowercasing, Mapping, Domain-basierte Zusammenführung\\
- Umgang mit Freitext-Antworten\\

\section{Kodierung und Transformation der Merkmale???}
- One-Hot-Encoding, Ordinal Encoding, ggf. Target-Encoding\\
- Skalierung (Transformation)\\
- Herausforderungen bei hochkardinalen Features\\



\chapter{Feature Engineering}

\section{Feature Selection}
OFFENE FRAGEN LÖSCHEN WIE "Why or why not?" oder "If yes..."
- Variance Threshold\\
- Korrelationen / Redundanz\\
- Relevanzbasierte Auswahl (Mutual Information)\\

\section{Feature Generation}
- Erstellen neuer Merkmale aus bestehenden Variablen\\
- Beispiele: Stress-Score, Support-Index, Arbeitsumfeld-Indikatoren\\
- Nutzen für Modellverständlichkeit und Clustering\\



\chapter{Dimensionsreduktion}
Warum Dimensionsreduktion?\\
Vorgehensweise\\

\section{Methoden der Dimensionsreduktion}
- PCA (linear)\\
- MDS, LLE (nichtlinear)\\
- Vergleich und Begründung der Auswahl\\

\section{Ergebnisse und Visualisierung}
- Erklärte Varianz (PCA)\\
- 2D/3D-Darstellungen\\
- Herausgearbeitete Muster und Trends\\



\chapter{Clustering}

\section{Auswahl geeigneter Methoden}
- K-Means\\
- Agglomeratives Clustering\\
- DBSCAN/HDBSCAN für komplexe Strukturen\\
- Begründung der Auswahl\\

\section{Bestimmung der Clusteranzahl}
- Elbow-Methode\\
- Silhouette Score\\
- Weitere Metriken\\

\section{Ergebnisse}
- Visualisierungen der Cluster (PCA/UMAP Scatterplots)\\
- Profiling: Beschreibung der typischen Merkmale jedes Clusters\\
- Identifikation gefährdeter Gruppen und Muster\\

\section{Übertragung auf HR-Kontext}
- Welcher Cluster ist besonders belastet?\\
- Welche Kombinationen von Faktoren treten gehäuft auf?\\
- Welche Gruppen könnten gezielte Unterstützung benötigen?\\













